# 1 机器学习相关

<font color=red size=6>**面试过程中遇到过的原题标红、加粗!!!**</font>

## 1.1 机器学习

- 介绍一个最熟悉的机器学习算法

- 决策树怎么建树，基尼系数公式

- [Adaboost](https://posts.careerengine.us/p/5d60ada2ce950354b320abde)拟合目标是什么

- Adaboost介绍一下，每个基学习器的权重怎么得到的

- 介绍下GBDT

- 介绍XGBoost

- 介绍下LightGBM

- LightGBM相对于XGBoost的改进

- GBDT中的梯度是什么，怎么用

- GBDT如何计算特征重要性

- GBDT讲一下，GBDT拟合残差，是真实的误差嘛，在什么情况下看做是真实的误差

- 介绍XGBoost中的并行

- 介绍XGBoost中精确算法与近似算法

- [XGBoost如何处理空缺值](https://www.zhihu.com/question/58230411)，为何要进行行采样、列采样

- 讲一下xgboost算法，xgboost是如何处理离散特征的，xgb怎么训练，xgb算法优点，怎么选特征，主要参数有哪些，xgb的特征重要性怎么看

- xgboost介绍一下，xgb对目标函数二阶泰勒展开，哪个是x，哪个是delta x, 一阶导和二阶导是对谁求得

- [为什么高维稀疏数据，LR比GBDT要好](https://blog.csdn.net/qq_28617019/article/details/83989326)

- 随机森林与GBDT采样的区别

- 随机森林中列采样的作用

- bagging与boosting对比, boosting和bagging的区别及分别适用于什么场景

- bagging与boosting分别从什么角度降低过拟合

- [逻辑回归如何避免过拟合](https://www.zhihu.com/question/269763205)

- 推导逻辑回归损失函数和损失函数求导

- [正则化项L1和L2为什么有用](https://blog.csdn.net/jinping_shi/article/details/52433975)

- l1正则不可导，如何优化

- 什么样的特征容易产生比较小的权重

- 随机森林采样n次，n趋于无穷大，oob样本的概率接近于？

- 逻辑回归与树模型的优缺点

- 对于高维稀疏数据，树模型能训练吗？一般怎么处理

- 树模型一般有哪些参数，分别有什么作用

- 随机森林如何处理空缺值

- 介绍kmeans，与其他聚类算法的对比

- 机器学习导致误差的原因？过拟合、欠拟合对应的偏差和方差是怎样的？

- 如何解决过拟合问题？哪些角度

- LR的原理，问题的假设，[为什么用交叉熵作为损失函数](https://blog.csdn.net/blogshinelee/article/details/103518097?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_antiscanv2&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_antiscanv2&utm_relevant_index=1)

- [LR损失函数写一下](https://blog.csdn.net/yz930618/article/details/104363705)

- LR是不是凸优化问题，如何判断LR达到最优值

- LR一般用什么数据，一般有什么特点(离散数据，离散化的一堆优点)

- LR，SVM, xgboost如何防止过拟合

- lr和树模型，离散特征和连续特征分别怎么处理

- lr和线性回归的区别

- 连续特征可以直接输入到lr中不? （归一化和标准化有什么区别）

- 线性回归可以求闭式解，逻辑回归可以吗，为什么，LR用什么求解参数，为什么要用梯度下降算法

- <font color=red>**SVM和LR的区别**</font>

- SVM的公式会推导嘛，SVM的损失函数

- SVM原理，为什么求最大间隔，为什么用核函数，常见的核函数及区别

- SVM支持向量怎么得到的

- 写一下SVM的原问题和对偶问题，分别解释一下

- SVM核函数有什么性质，写一下SVM核化的形式

- 无监督学习，半监督学习，有监督学习的区别

- 有哪些无监督学习的方法（kmeans,pca,生成模型，自编码器）

- 有哪些回归模型（多项式回归，树模型，svr, 神经网络）

- 生成模型、判别模型的区别

- [概率和似然的区别](https://blog.csdn.net/songyu0120/article/details/85059149)

- 最大似然估计和后验概率的区别，分别用LR来推导损失函数的话有什么区别（乘以W的先验概率）

- 朴素贝叶斯介绍，朴素贝叶斯公式，为什么朴素

- l1,l2特性及原理，分别适用于那些场合

- 给一个多峰数据场景，为什么l2不适合，可以怎么解决

- 讲讲Kmeans、EM算法

- 机器学习中怎么解决过拟合，DNN中怎么解决

- 说一下SVD怎么降维

- 推导softmax做激活函数求导

- LR，SVM,xgb哪个对样本不平衡不太敏感，顺便把SVM和xgb介绍了

- 降维方法了解嘛，PCA? 为什么取特征值前k大的对应的特征向量组成的矩阵？低秩表示


## 补充：机器学习面试题

1. 请简述过拟合、欠拟合的定义；
2. [判别模型与生成模型有什么区别，列举几个你熟悉的生成模型；](https://www.zhihu.com/question/20446337)
3. 监督学习、非监督学习和半监督学习的定义，并列举分别列举几个对应的模型；
4. [请解释下维度灾难的情况；](https://zhuanlan.zhihu.com/p/26945814)
5. [列举一个余弦相似度的应用场景；](https://blog.csdn.net/leitouguan8655/article/details/80589654)
6. [训练集/验证集/测试集有什么区别，如何进行划分的？](https://zhuanlan.zhihu.com/p/48976706)
7. [机器学习算法如何测试，如何设计一个合理的A/B 测试？](https://blog.csdn.net/weixin_42137700/article/details/91042370)
8. SVM 和SVR 的公式推导
9. SVM 的软间隔问题
10. L1 正则为什么能让系数变为0，L1 正则怎么处理0 点不可导的情形；
11. 如何对数值特定进行归一化，有哪些归一化方法？
12. 类别特征如何编码？
13. 业务场景下如何构建如何特征，如何验证特征的有效性？
14. 如何对高维特征进行降维，以及有哪些特征选择的方法？
15. 线性回归与逻辑回归有什么区别和联系？
16. 最小二乘法的推导；
17. 树模型是如何选择最优的分裂节点的？
18. 树模型有哪些防止过拟合的方式？
19. 树模型比较适合何种类型的数据，分类树和回归树有什么区别？
20. 请分别叙述随机森林、XGBoost、LightGBM 的异同点；
21. 请简述EarlyStop 的工作机制；
22. 请简述bagging 和boosting 的原理和应用场景；
23. 推荐系统的原理是什么，常用的推荐算法有哪些？
24. 请解释下卷积和反卷级操作的原理和用途；
25. 什么是残差网络结构，如何设计的？
26. 什么是梯度消失/梯度爆炸现象，如何避免？
27. 请简述神经网络常用的优化方法；

## 1.2 深度学习

- 梯度是什么，hessian矩阵怎么求
- [模型不收敛的原因及解决办法。](https://zhuanlan.zhihu.com/p/285601835)
- 有没有上过凸优化的课程，如何判断凸函数
- [防止过拟合的策略有哪些](https://blog.csdn.net/heyongluoyao8/article/details/49429629)
- [dropout怎么防止过拟合, Dropout在训练和测试区别](https://www.cnblogs.com/zingp/p/11631913.html)
- BN介绍，BN怎么防止过拟合，怎么用的，参数量, 参数怎么得到的
- [优化器，SGD与Adam的异同点](https://blog.csdn.net/zhoukaiyin_hzau/article/details/104130452)
- [介绍一下你了解的激活函数以及优缺点](https://blog.csdn.net/GreatXiang888/article/details/99296607)
- [介绍一下深度学习的优化器发展史, 及常见的优化算法](https://blog.csdn.net/racesu/article/details/106382892)
- [梯度爆炸和梯度消失问题](https://zhuanlan.zhihu.com/p/72589432)
- [SGD缺点，已经有什么改进的优化器](https://blog.csdn.net/yinyu19950811/article/details/90476956)
- [网络权重初始化为0有什么影响，初始化为一个非0的常数呢？](https://blog.csdn.net/qzq2514/article/details/104518773)
- [embedding如何设置维度？越大越好还是越小越好？](https://www.zhihu.com/question/60648826)
- [transformer中计算attention除于根号d的作用](https://blog.csdn.net/suibianshen2012/article/details/122141294)
- [embedding如何训练](http://fancyerii.github.io/books/word-embedding/)
- [介绍下attention，相比cnn、lstm的优势](https://zhuanlan.zhihu.com/p/91839581)
- word2vec如何进行负采样
- word2vec两种训练方法的区别，具体损失函数
- [介绍LSTM每一个门的具体操作，一个LSTM cell的时间复杂度是多少](https://blog.csdn.net/yimingsilence/article/details/82027396)
- [transformer中encoder和decoder的输入分别是什么](https://zhuanlan.zhihu.com/p/166608727)
- transformer中encoder与decoder的QKV矩阵如何产生
- transformer中QKV矩阵是否可以设置成同一个
- transformer与bert的位置编码有什么区别
- BERT中计算attention的公式
- BERT中LayerNorm的作用，为什么不用BN？
- BERT中的两种预训练任务介绍
- 深度学习中BN的好处？最早提出BN是为了解决什么问题？BN具体怎么实现的
- 激活函数中，sigmoid，tanh有什么不好的地方？relu有什么优势？
- pagerank相比于tf-idf的优势
- 画一下LSTM的结构图
- RNN和LSTM的区别，解决了什么问题，为什么解决了梯度消失的问题
- 深度模型和传统机器学习模型对数据量的要求，什么场景用什么模型



## 1.3 特征工程

- [特征工程一般怎么做](https://blog.csdn.net/Dream_angel_Z/article/details/49388733)
- 特征数值分布比较稀疏如何处理
- [正负样本不均衡如何处理](https://mdnice.com/writing/f5cfcf76038d4a91a902184869660118)
- 连续特征离散化的作用
- [对id类特征onehot导致维度过高，如何处理？](https://www.zhihu.com/question/34819617)
- [如何进行特征筛选](https://zhuanlan.zhihu.com/p/74198735)
- DNN能做特征交叉嘛
- 海量类别特征该如何处理，有什么方法
- pearson系数
- 归一化和标准化有什么区别
- 如果不使用最近邻检索的库，你会怎么做最近邻检索



## 1.4 评估指标

- [auc的含义和计算方法, 有没有更快的计算方法](https://www.zhihu.com/question/30643044/answer/510317055)
- AUC会不会出现小于0.5的情况，出现了怎么调bug
- AUC为1可能是由什么导致的？
- [分类评估指标中，F1和AUC有什么区别](https://blog.csdn.net/Jerry_Lu_ruc/article/details/107912462)
- 分类指标用的什么，哪个分类指标对正负样本分布不敏感
- 如果对负样本进行采样，auc的计算结果会发生变化吗
- [交叉熵跟MSE有什么区别](https://blog.csdn.net/weixin_41888257/article/details/104894141)
- [micro-f1解释](https://blog.csdn.net/qq_43190189/article/details/105778058)
- [介绍下排序指标ndcg](https://blog.csdn.net/u013185349/article/details/102142950)
- [回归指标应该用什么](https://zhuanlan.zhihu.com/p/143169742)
- AUC和precision,recall，F1的区别，不同情况怎么选择指标
- [Group auc了解嘛](https://blog.csdn.net/hnu2012/article/details/87892368)
- 给数据计算AUC
- 分类评价指标，TPR,FPR等的含义